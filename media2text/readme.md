# ğŸ“š Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ Ù¾Ø±ÙˆÚ˜Ù‡ Fine-tuning Whisper

---

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ Ù¾Ø±ÙˆÚ˜Ù‡
Fine-tuning Ù…Ø¯Ù„ Whisper Large V3 Ø¨Ø±Ø§ÛŒ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 1327 Ù†Ù…ÙˆÙ†Ù‡ ØµÙˆØªÛŒ (89 Ø¯Ù‚ÛŒÙ‚Ù‡)

---

## ğŸ“‹ Ù…Ø±Ø§Ø­Ù„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡

### 1ï¸âƒ£ Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Docker + NVIDIA

```bash
# Ù†ØµØ¨ Docker
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io

# Ù†ØµØ¨ NVIDIA Container Toolkit
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
echo "deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://nvidia.github.io/libnvidia-container/stable/deb/amd64 /" | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt update
sudo apt install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

# ØªØ³Øª GPU
docker run --rm --gpus all nvidia/cuda:12.0.0-base-ubuntu22.04 nvidia-smi
```

---

### 2ï¸âƒ£ Ø³Ø§Ø®Øª Docker Container

**Dockerfile:**
```dockerfile
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=Asia/Tehran

RUN apt-get update && apt-get install -y \
    python3.10 python3-pip ffmpeg git vim wget curl \
    && rm -rf /var/lib/apt/lists/*

RUN pip3 install --upgrade pip

RUN pip3 install --no-cache-dir \
    torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

RUN pip3 install --no-cache-dir \
    openai-whisper faster-whisper transformers accelerate \
    datasets evaluate jiwer tensorboard gradio pydub \
    numpy pandas python-Levenshtein rapidfuzz python-docx

WORKDIR /workspace
EXPOSE 7860 6006
CMD ["/bin/bash"]
```

**docker-compose.yml:**
```yaml
services:
  whisper-stable:
    build: .
    image: whisper-stable:latest
    container_name: whisper-stable
    restart: unless-stopped
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - HF_HOME=/workspace/models
      - TRANSFORMERS_CACHE=/workspace/models
      
    volumes:
      - ./data:/workspace/data
      - ./models:/workspace/models
      - ./output:/workspace/output
      - ./scripts:/workspace/scripts
      - whisper_cache:/root/.cache
      
    working_dir: /workspace
    stdin_open: true
    tty: true
    ports:
      - "7860:7860"
      - "6006:6006"

volumes:
  whisper_cache:
    driver: local
```

**Ø³Ø§Ø®Øª Ùˆ Ø§Ø¬Ø±Ø§:**
```bash
cd ~/whisper-project
docker compose build
docker compose up -d
docker compose exec whisper-stable bash
```

---

### 3ï¸âƒ£ Mount Ú©Ø±Ø¯Ù† Windows Share

```bash
# Ù†ØµØ¨ Ø§Ø¨Ø²Ø§Ø±
sudo apt install -y cifs-utils

# Mount
sudo mkdir -p /mnt/share
sudo mount -t cifs //172.18.40.150/share /mnt/share \
  -o username=s.tabatabaei,password=Fxxxxxxxxxxx,domain=QABAS.net,vers=3.0,uid=0,gid=0,file_mode=0777,dir_mode=0777

# Mount Ø¯Ø§Ø¦Ù…ÛŒ
echo "username=s.tabatabaei" | sudo tee /root/.smbcredentials
echo "password=Fxxxxxxxxxx" | sudo tee -a /root/.smbcredentials
echo "domain=QABAS.net" | sudo tee -a /root/.smbcredentials
sudo chmod 600 /root/.smbcredentials

# Ø§Ø¶Ø§ÙÙ‡ Ø¨Ù‡ fstab
echo "//172.18.40.150/share /mnt/share cifs credentials=/root/.smbcredentials,vers=3.0,uid=0,gid=0,file_mode=0777,dir_mode=0777,_netdev 0 0" | sudo tee -a /etc/fstab
```

---

### 4ï¸âƒ£ Ú©Ù¾ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§

```bash
# Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
mkdir -p ~/whisper-project/data/raw

# Ú©Ù¾ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
cp /mnt/share/471*.txt ~/whisper-project/data/raw/471.txt
cp /mnt/share/471*.srt ~/whisper-project/data/raw/471.srt
cp /mnt/share/471*.wav ~/whisper-project/data/raw/471.wav

cp /mnt/share/*215*.txt ~/whisper-project/data/raw/215.txt
cp /mnt/share/*215*.srt ~/whisper-project/data/raw/215.srt
cp /mnt/share/*215*.wav ~/whisper-project/data/raw/215.wav
```

---

### 5ï¸âƒ£ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯ÛŒØªØ§Ø³Øª

**Ø§Ø³Ú©Ø±ÛŒÙ¾Øª `/workspace/scripts/process_all.py`:**
- Parse Ú©Ø±Ø¯Ù† SRT Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±
- ØªØ·Ø¨ÛŒÙ‚ SRT Ø¨Ø§ Ù…ØªÙ† Ù…Ø±Ø¬Ø¹ (Fuzzy Matching)
- Ø¨Ø±Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ SRT ØªØµØ­ÛŒØ­ Ø´Ø¯Ù‡
- ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† (1-30 Ø«Ø§Ù†ÛŒÙ‡)
- Ø­Ø°Ù Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ùˆ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡

**Ù†ØªÛŒØ¬Ù‡:**
- âœ… 1327 Ù‚Ø·Ø¹Ù‡ ØµÙˆØªÛŒ
- âœ… 710 Ù‚Ø·Ø¹Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ 471
- âœ… 617 Ù‚Ø·Ø¹Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ 215
- âœ… Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„: 4 Ø«Ø§Ù†ÛŒÙ‡
- âœ… Ù…Ø¯Øª Ú©Ù„: 89.2 Ø¯Ù‚ÛŒÙ‚Ù‡

---

### 6ï¸âƒ£ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ HuggingFace Dataset

**Ø§Ø³Ú©Ø±ÛŒÙ¾Øª `/workspace/scripts/create_hf_dataset.py`:**
```python
# ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/validation/test (80/10/10)
# Cast audio Ø¨Ù‡ Audio(sampling_rate=16000)
# Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± /workspace/data/hf_dataset
```

**Ù†ØªÛŒØ¬Ù‡:**
- Train: 1061 Ù†Ù…ÙˆÙ†Ù‡ (80%)
- Validation: 133 Ù†Ù…ÙˆÙ†Ù‡ (10%)
- Test: 133 Ù†Ù…ÙˆÙ†Ù‡ (10%)

---

### 7ï¸âƒ£ Fine-tuning Whisper

**Ø§Ø³Ú©Ø±ÛŒÙ¾Øª `/workspace/scripts/train.py`:**

**ØªÙ†Ø¸ÛŒÙ…Ø§Øª:**
```python
MODEL_NAME = "openai/whisper-large-v3"
LANGUAGE = "persian"
TASK = "transcribe"

# Training Args:
- per_device_train_batch_size: 4
- gradient_accumulation_steps: 2
- learning_rate: 1e-5
- max_steps: 5000
- fp16: True
- evaluation_strategy: steps (Ù‡Ø± 500 step)
- metric: WER (Word Error Rate)
```

**Ø§Ø¬Ø±Ø§:**
```bash
# Ø¯Ø§Ø®Ù„ container
python3 /workspace/scripts/train.py
```

**Ø²Ù…Ø§Ù† ØªÙ‚Ø±ÛŒØ¨ÛŒ:** 4-7 Ø³Ø§Ø¹Øª (Ø¨Ø§ RTX 4090)

---

## ğŸ“ Ø³Ø§Ø®ØªØ§Ø± Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø±ÙˆÚ˜Ù‡

```
~/whisper-project/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
â”‚   â”‚   â”œâ”€â”€ 471.txt
â”‚   â”‚   â”œâ”€â”€ 471.srt
â”‚   â”‚   â”œâ”€â”€ 471.wav
â”‚   â”‚   â”œâ”€â”€ 215.txt
â”‚   â”‚   â”œâ”€â”€ 215.srt
â”‚   â”‚   â””â”€â”€ 215.wav
â”‚   â”œâ”€â”€ processed/              # Ø¯ÛŒØªØ§Ø³Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
â”‚   â”‚   â”œâ”€â”€ dataset_471/
â”‚   â”‚   â”‚   â”œâ”€â”€ audio/          # 710 ÙØ§ÛŒÙ„ WAV
â”‚   â”‚   â”‚   â””â”€â”€ transcripts/    # 710 ÙØ§ÛŒÙ„ TXT
â”‚   â”‚   â”œâ”€â”€ dataset_215/
â”‚   â”‚   â”‚   â”œâ”€â”€ audio/          # 617 ÙØ§ÛŒÙ„ WAV
â”‚   â”‚   â”‚   â””â”€â”€ transcripts/    # 617 ÙØ§ÛŒÙ„ TXT
â”‚   â”‚   â”œâ”€â”€ 471_corrected.srt
â”‚   â”‚   â”œâ”€â”€ 215_corrected.srt
â”‚   â”‚   â””â”€â”€ all_segments.json
â”‚   â””â”€â”€ hf_dataset/             # HuggingFace Dataset
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ validation/
â”‚       â””â”€â”€ test/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ process_all.py          # Ù¾Ø±Ø¯Ø§Ø²Ø´ SRT Ùˆ Ø¨Ø±Ø´ ØµÙˆØª
â”‚   â”œâ”€â”€ create_hf_dataset.py    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ HF Dataset
â”‚   â””â”€â”€ train.py                # Fine-tuning
â”œâ”€â”€ output/
â”‚   â””â”€â”€ whisper-persian/        # Ù…Ø¯Ù„ Fine-tuned Ø´Ø¯Ù‡
â”‚       â”œâ”€â”€ pytorch_model.bin
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ preprocessor_config.json
â”‚       â””â”€â”€ ...
â””â”€â”€ models/                     # Cache Ù…Ø¯Ù„â€ŒÙ‡Ø§
```

---

## ğŸš€ Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…Ù‡Ù…

```bash
# ÙˆØ±ÙˆØ¯ Ø¨Ù‡ container
docker compose exec whisper-stable bash

# Ù…Ø§Ù†ÛŒØªÙˆØ± GPU
nvidia-smi

# TensorBoard
tensorboard --logdir /workspace/output/whisper-persian --host 0.0.0.0

# Ú†Ú© Ú©Ø±Ø¯Ù† Ù¾ÛŒØ´Ø±ÙØª
ls -lh /workspace/output/whisper-persian/checkpoint-*
```

---

## ğŸ“Š Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ

| Ù…Ø´Ø®ØµÙ‡ | Ù…Ù‚Ø¯Ø§Ø± |
|-------|-------|
| Ú©Ù„ Ø¯ÛŒØªØ§Ø³Øª | 1327 Ù†Ù…ÙˆÙ†Ù‡ |
| Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ú©Ù„ | 89.2 Ø¯Ù‚ÛŒÙ‚Ù‡ |
| Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ | 4 Ø«Ø§Ù†ÛŒÙ‡ |
| Train | 1061 Ù†Ù…ÙˆÙ†Ù‡ |
| Validation | 133 Ù†Ù…ÙˆÙ†Ù‡ |
| Test | 133 Ù†Ù…ÙˆÙ†Ù‡ |
| Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ | Whisper Large V3 |
| GPU | RTX 4090 (24GB) |
| Ø²Ù…Ø§Ù† Training | ~5 Ø³Ø§Ø¹Øª |

---

## ğŸ¯ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯: Upload Ø¨Ù‡ HuggingFace

```bash
# Ù†ØµØ¨ huggingface_hub
pip install huggingface_hub

# Login
huggingface-cli login

# Upload
python3 << EOF
from huggingface_hub import HfApi
api = HfApi()
api.create_repo("whisper-large-v3-persian-finetuned")
api.upload_folder(
    folder_path="/workspace/output/whisper-persian",
    repo_id="YOUR_USERNAME/whisper-large-v3-persian-finetuned",
    repo_type="model"
)
EOF
```

---

**Ø§ÛŒÙ† Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø³Øª! âœ…**