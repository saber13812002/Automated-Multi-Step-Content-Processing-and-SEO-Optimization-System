import os
import json
import glob
from pathlib import Path
from typing import List, Dict
import librosa
import soundfile as sf

def split_audio_by_silence(audio_path: str, output_dir: str, 
                           min_silence_len: float = 0.5,
                           silence_thresh: float = -40) -> List[str]:
    """ØªÙ‚Ø³ÛŒÙ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ú©ÙˆØª
    
    Returns: Ù„ÛŒØ³Øª Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Ù‡
    """
    from pydub import AudioSegment
    from pydub.silence import split_on_silence
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„
    audio = AudioSegment.from_file(audio_path)
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ú©ÙˆØª
    chunks = split_on_silence(
        audio,
        min_silence_len=int(min_silence_len * 1000),  # Ø¨Ù‡ Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡
        silence_thresh=silence_thresh,
        keep_silence=200  # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† 200ms Ø³Ú©ÙˆØª
    )
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù‚Ø·Ø¹Ø§Øª
    output_paths = []
    base_name = Path(audio_path).stem
    
    for i, chunk in enumerate(chunks):
        if len(chunk) < 500:  # Ú©Ù…ØªØ± Ø§Ø² 0.5 Ø«Ø§Ù†ÛŒÙ‡ Ø±Ø¯ Ù…ÛŒØ´Ù‡
            continue
        if len(chunk) > 30000:  # Ø¨ÛŒØ´ØªØ± Ø§Ø² 30 Ø«Ø§Ù†ÛŒÙ‡ Ø±Ø¯ Ù…ÛŒØ´Ù‡
            continue
            
        output_path = os.path.join(output_dir, f"{base_name}_chunk_{i:04d}.wav")
        chunk.export(output_path, format="wav")
        output_paths.append(output_path)
    
    return output_paths

def create_dataset_structure(
    wav_directory: str,
    output_base_dir: str = "./whisper_dataset",
    split_audio: bool = True
):
    """Ø³Ø§Ø®Øª Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Fine-tuning Whisper
    
    Ø³Ø§Ø®ØªØ§Ø± Ø®Ø±ÙˆØ¬ÛŒ:
    whisper_dataset/
    â”œâ”€â”€ audio/           # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ
    â”œâ”€â”€ transcripts/     # Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… (Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ø¯Ø³ØªÛŒ)
    â””â”€â”€ metadata.jsonl   # ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø¯ÛŒØªØ§Ø³Øª
    """
    
    # Ø³Ø§Ø®Øª Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§
    audio_dir = os.path.join(output_base_dir, "audio")
    transcript_dir = os.path.join(output_base_dir, "transcripts")
    os.makedirs(audio_dir, exist_ok=True)
    os.makedirs(transcript_dir, exist_ok=True)
    
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ WAV
    wav_files = glob.glob(os.path.join(wav_directory, "**/*.wav"), recursive=True)
    print(f"ğŸ“ ØªØ¹Ø¯Ø§Ø¯ {len(wav_files)} ÙØ§ÛŒÙ„ WAV Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
    
    all_segments = []
    
    for idx, wav_file in enumerate(wav_files):
        print(f"âš™ï¸  Ù¾Ø±Ø¯Ø§Ø²Ø´ {idx+1}/{len(wav_files)}: {Path(wav_file).name}")
        
        if split_audio:
            # ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª Ú©ÙˆÚ†Ú©
            try:
                chunks = split_audio_by_silence(wav_file, audio_dir)
                print(f"   âœ‚ï¸  {len(chunks)} Ù‚Ø·Ø¹Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
            except Exception as e:
                print(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ‚Ø³ÛŒÙ…: {e}")
                chunks = []
        else:
            # Ú©Ù¾ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
            import shutil
            dest = os.path.join(audio_dir, Path(wav_file).name)
            shutil.copy2(wav_file, dest)
            chunks = [dest]
        
        # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù‚Ø·Ø¹Ù‡
        for chunk_path in chunks:
            chunk_name = Path(chunk_path).stem
            transcript_path = os.path.join(transcript_dir, f"{chunk_name}.txt")
            
            # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ Ø®Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ø¯Ø³ØªÛŒ
            with open(transcript_path, 'w', encoding='utf-8') as f:
                f.write("")  # Ø®Ø§Ù„ÛŒ - Ø¨Ø§ÛŒØ¯ Ø¯Ø³ØªÛŒ Ù¾Ø± Ø¨Ø´Ù‡
            
            all_segments.append({
                "audio": chunk_path,
                "transcript": transcript_path,
                "duration": librosa.get_duration(path=chunk_path)
            })
    
    # Ø°Ø®ÛŒØ±Ù‡ metadata
    metadata_path = os.path.join(output_base_dir, "segments_info.json")
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(all_segments, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒØªØ§Ø³Øª Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯!")
    print(f"ğŸ“‚ Ù…Ø³ÛŒØ±: {output_base_dir}")
    print(f"ğŸµ ØªØ¹Ø¯Ø§Ø¯ Ù‚Ø·Ø¹Ø§Øª: {len(all_segments)}")
    print(f"\nâš ï¸  Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯ÛŒ:")
    print(f"   1. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ TXT Ø¯Ø± {transcript_dir} Ø±Ø§ Ø¨Ø§ Ù…ØªÙ† ØµØ­ÛŒØ­ Ù¾Ø± Ú©Ù†ÛŒØ¯")
    print(f"   2. Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ø¹Ø¯ÛŒ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯: prepare_for_training.py")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--wav-dir", required=True, help="Ù¾ÙˆØ´Ù‡ Ø­Ø§ÙˆÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ WAV")
    parser.add_argument("--output-dir", default="./whisper_dataset", help="Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯ÛŒØªØ§Ø³Øª")
    parser.add_argument("--no-split", action="store_true", help="ØªÙ‚Ø³ÛŒÙ… Ù†Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§")
    
    args = parser.parse_args()
    
    create_dataset_structure(
        args.wav_dir,
        args.output_dir,
        split_audio=not args.no_split
    )