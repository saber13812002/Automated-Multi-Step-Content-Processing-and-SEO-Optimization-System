<!-- e2e517dd-b4eb-498a-b011-22e162f5932d 50a26b3c-191a-4455-89e7-b40f8b707f37 -->
# طرح ارتقای امبدینگ و پایش داده

## مراحل اصلی

1. **بازبینى الگوریتم فعلی** – مستندسازی جزییات `build_segments` و سناریوهای max/context در `export-sql-chromadb/export-sql-backup-to-chromadb.py`، ثبت فرضیات برای متن‌های فارسی/عربی.
2. **ابزار آمارگیری مستقل** – ایجاد ماژول/CLI (مثلاً `export-sql-chromadb/dataset_stats.py`) با تابع `print_dataset_stats(sql_path, max_length, context, segments_per_second)` که:

- از `iter_book_pages` و تعریف «خط» مبتنی بر شمارش `\n` پس از `html_to_text` استفاده کند.
- تعداد رکورد، کتاب، پاراگراف و سگمنت را محاسبه کند و توزیع طول/خط را در JSON و خروجی ترمینال گزارش دهد.
- زمان تقریبی امبدینگ را با سنجش نرخ واقعی (ارسال حداقل ۱۰ سند به کالکشن تست برای هر مدل؛ فعلاً small≈۱h، large≈۲h) محاسبه کند.

3. **تست‌های Glue برای مدل لوکال** – افزودن اسکریپت تست (مثلاً `tests/test_paragraph_glue.py`) که دو سناریو (پاراگراف مستقل و پاراگراف چسبیده ≥۳ خط) را اجرا کند، از مدل HuggingFace لوکال امبدینگ بگیرد و شاخص‌های شباهت/کاهش سگمنت را چاپ کند.
4. **بهبود سگمنتیشن و وزن‌دهی** – توسعه ماژول chunking برای:

- شناسایی تیترها و افزودن `metadata["importance"]` و استفاده از reranking متکی بر metadata.
- ادغام پاراگراف‌های کوتاه با بعدی تا عبور از آستانه خطوط/کاراکتر.
- اضافه کردن سند کامل هر صفحه (metadata `page_level=True`) در کالکشن اصلی، با قابلیت پاک‌کردن در صورت نیاز.

5. **بنچمارک، پاکسازی و گزارش‌دهی** –

- ایجاد اسکریپت بنچمارک (مثلاً `tools/benchmark_embeddings.py`) برای مقایسه کیفیت قبل/بعد روی کالکشن تست.
- افزودن ابزار/روند برای حذف jobهای ناموفق و پاک‌سازی کالکشن‌های تستی ناخواسته از طریق وب‌ادمین یا CLI.
- نتایج و نرخ‌های جدید را در گزارش (مثل `REPORT_embedding_stats.md`) ثبت کنید.

6. **به‌روزرسانی مستندات** – در `README.web_service.md`, `FEATURES.md` و صفحات ادمین نحوه اجرای ابزار آمارگیری، تست glue، تنظیمات وزن‌دهی و فیچرهای پاکسازی را توضیح دهید.

## وضعیت ابهامات

- خط پاراگراف: شمارش `\n` در متن خروجی `html_to_text`.
- نرخ پردازش: اندازه‌گیری برای هر مدل با ارسال ≥۱۰ سند آزمایشی (داده فعلی small≈۱h، large≈۲h).
- دامنه اجرا: تحلیل عملی روی `books_pages_mini.sql` و تعمیم نتایج برای dump کامل.
- وزن‌دهی تیتر: ابتدا با metadata + rerank، اصلاح متن فقط در صورت لزوم.
- سند کامل صفحه: در کالکشن اصلی ذخیره می‌شود و در صورت بروز مشکل قابل حذف است.
- قابلیت پاکسازی: فیچرهایی برای حذف jobهای خراب و کالکشن‌های غیرضروری به ادمین افزوده می‌شود.

### To-dos

- [ ] بازبینى build_segments و مستندسازی رفتار فعلی
- [ ] ایجاد ابزار آمارگیری و گزارش JSON
- [ ] نوشتن تست Glue و مدل لوکال
- [ ] پیاده‌سازی وزن تیتر، ادغام پاراگراف و سند صفحه
- [ ] بنچمارک کیفیت و فیچر پاکسازی
- [ ] به‌روزرسانی اسناد نحوه استفاده