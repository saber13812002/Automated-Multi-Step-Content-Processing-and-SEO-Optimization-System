import whisper
from pydub import AudioSegment
import datetime
import sys
import argparse
from pathlib import Path
import glob
import os
import torch
import concurrent.futures
from typing import List, Tuple

def format_timestamp(seconds):
    return str(datetime.timedelta(seconds=seconds)).replace('.', ',')[:11]

def get_available_gpus() -> List[int]:
    """Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒØ³Øª GPU Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯"""
    return list(range(torch.cuda.device_count()))

def process_file_with_gpu(args: Tuple[str, str, str, int]) -> bool:
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© ÙØ§ÛŒÙ„ Ø¨Ø§ GPU Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡"""
    video_file, model_name, language, gpu_id = args
    try:
        # ØªÙ†Ø¸ÛŒÙ… GPU ÙÙ‚Ø· Ø§Ú¯Ø± GPU Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª
        if gpu_id != -1:
            torch.cuda.set_device(gpu_id)
        model = whisper.load_model(model_name)
        
        result = model.transcribe(video_file, language=language)
        output_file = Path(video_file).with_suffix('.srt')
        
        with open(output_file, 'w', encoding='utf-8') as srt_file:
            for j, segment in enumerate(result['segments'], start=1):
                start_time = format_timestamp(segment['start'])
                end_time = format_timestamp(segment['end'])
                text = segment['text'].strip()
                srt_file.write(f"{j}\n{start_time} --> {end_time}\n{text}\n\n")
        
        print(f'âœ… Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ø¯Ø± ÙØ§ÛŒÙ„ {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ (GPU {gpu_id})')
        return True
    except Exception as e:
        print(f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {video_file} Ø±ÙˆÛŒ GPU {gpu_id}: {str(e)}')
        return False

def process_directory(directory_path='.', model_name='large', language='ar'):
    print("ğŸ¬ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯! Ø³ÛŒØ³ØªÙ… ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Whisper Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯...")
    print("=" * 60)
    
    # Ø¨Ø±Ø±Ø³ÛŒ GPU Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
    available_gpus = get_available_gpus()
    if not available_gpus:
        print("âš ï¸  Ù‡ÛŒÚ† GPU Ø§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² CPU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        available_gpus = [-1]  # CPU
    else:
        print(f"ğŸ® ØªØ¹Ø¯Ø§Ø¯ {len(available_gpus)} Ú©Ø§Ø±Øª Ú¯Ø±Ø§ÙÛŒÚ© ÛŒØ§ÙØª Ø´Ø¯: {available_gpus}")

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ§ - Ø´Ø§Ù…Ù„ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ
    extensions = [
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ
        '*.mp4', '*.mp3', '*.m4a', '*.wav', '*.aac', '*.flac', '*.ogg', '*.mkv', '*.webm', '*.avi', '*.mov', '*.mpg',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ùˆ Ù¾Ø®Ø´
        '*.ts', '*.mts', '*.m2ts', '*.trp', '*.tp',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù¾Ø®Ø´
        '*.mxf', '*.gxf',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ DVD Ùˆ Ø¶Ø¨Ø·
        '*.vob', '*.ifo', '*.vro', '*.vdr',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ùˆ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡
        '*.3gp', '*.3g2',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª
        '*.asf', '*.wmv', '*.wma',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ RealMedia
        '*.rm', '*.rmvb', '*.ra', '*.ram',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø¶Ø¨Ø· ØªÙ„ÙˆÛŒØ²ÛŒÙˆÙ†
        '*.dvr-ms', '*.wtv', '*.rec', '*.pvr',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ú©ÙˆØ±Ø¯
        '*.mod', '*.tod',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ MPEG Ø§Ø¶Ø§ÙÛŒ
        '*.m2v', '*.m1v', '*.mp2', '*.mpa',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        '*.ac3', '*.eac3', '*.dts', '*.dtshd',
        '*.thd', '*.mlp', '*.aiff', '*.au', '*.snd',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Audible Ùˆ Ú©ØªØ§Ø¨ ØµÙˆØªÛŒ
        '*.aa', '*.aax', '*.m4b', '*.m4p',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§Ù„Ø§
        '*.opus', '*.spx', '*.tta', '*.tak',
        '*.wv', '*.ape', '*.shn'
    ]
    all_files = []
    for ext in extensions:
        all_files.extend(glob.glob(os.path.join(directory_path, f'**/{ext}'), recursive=True))
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯Ù‡
    files_to_process = [f for f in all_files if not Path(f).with_suffix('.srt').exists()]
    
    if not files_to_process:
        print("âœ… Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù…Ø¯ÛŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return

    print(f"ğŸ“ ØªØ¹Ø¯Ø§Ø¯ {len(files_to_process)} ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ¯Ø§ Ø´Ø¯.")
    print("=" * 60)

    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ
    tasks = []
    for i, video_file in enumerate(files_to_process):
        gpu_id = available_gpus[i % len(available_gpus)]
        tasks.append((video_file, model_name, language, gpu_id))

    print(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ {len(files_to_process)} ÙØ§ÛŒÙ„...")
    print("=" * 60)

    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
    with concurrent.futures.ProcessPoolExecutor(max_workers=len(available_gpus)) as executor:
        results = list(executor.map(process_file_with_gpu, tasks))

    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
    successful = sum(1 for r in results if r)
    failed = len(files_to_process) - successful
    
    print("=" * 60)
    print(f"ğŸ‰ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print(f"âœ… Ù…ÙˆÙÙ‚: {successful} ÙØ§ÛŒÙ„")
    print(f"âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {failed} ÙØ§ÛŒÙ„")
    print(f"ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹: {len(files_to_process)} ÙØ§ÛŒÙ„")
    print("=" * 60)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ùˆ ØµÙˆØªÛŒ Ø¨Ù‡ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Whisper')
    parser.add_argument('--directory', default='.', help='Ù…Ø³ÛŒØ± Ù¾ÙˆØ´Ù‡ Ø­Ø§ÙˆÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ùˆ ØµÙˆØªÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ù¾ÙˆØ´Ù‡ ÙØ¹Ù„ÛŒ)')
    parser.add_argument('--model', default='large', help='Ù†Ø§Ù… Ù…Ø¯Ù„ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: large)')
    parser.add_argument('--language', default='ar', help='Ú©Ø¯ Ø²Ø¨Ø§Ù† (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: ar)')
    
    args = parser.parse_args()
    
    process_directory(args.directory, args.model, args.language)