import whisper
from pydub import AudioSegment
import datetime
import sys
import argparse
from pathlib import Path
import glob
import os
import torch
import concurrent.futures
import subprocess
import tempfile
from typing import List, Tuple, Optional

def format_timestamp(seconds):
    return str(datetime.timedelta(seconds=seconds)).replace('.', ',')[:11]

def get_available_gpus() -> List[int]:
    """Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒØ³Øª GPU Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯"""
    return list(range(torch.cuda.device_count()))

def extract_audio_with_ffmpeg(input_path: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØµÙˆØª Ø¨Ù‡ WAV Ø¨Ø§ ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ÛŒÙˆØ¨/ØºÛŒØ±Ù…Ø¹Ù…ÙˆÙ„.

    Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ WAV Ù…ÙˆÙ‚Øª Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØªØ› ÙˆÚ¯Ø±Ù†Ù‡ None
    """
    input_path_str = str(input_path)
    tmp_wav_path = str(Path(input_path_str).with_suffix('.whisper.tmp.wav'))

    def run_ffmpeg(cmd: List[str]) -> bool:
        try:
            result = subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, check=False)
            return result.returncode == 0
        except Exception:
            return False

    # ØªÙ„Ø§Ø´ Ø§ÙˆÙ„: Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ† Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ
    base_args = [
        'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error', '-nostdin',
        '-analyzeduration', '100M', '-probesize', '100M',
        '-fflags', '+igndts+discardcorrupt', '-err_detect', 'ignore_err',
        '-i', input_path_str,
        '-vn', '-ac', '1', '-ar', '16000', tmp_wav_path
    ]
    if run_ffmpeg(base_args):
        return tmp_wav_path

    # ØªÙ„Ø§Ø´ Ø¯ÙˆÙ…: Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù…Ø§Ù†Ù†Ø¯ TS Ø¨Ø§Ø´Ø¯ Ø§Ù…Ø§ Ù¾Ø³ÙˆÙ†Ø¯ MP4 Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ ÙØ±Ù…Øª ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ mpegts ÙØ±Ø¶ Ú©Ù†
    ts_args = [
        'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error', '-nostdin',
        '-analyzeduration', '200M', '-probesize', '200M',
        '-fflags', '+igndts+discardcorrupt', '-err_detect', 'ignore_err',
        '-f', 'mpegts', '-i', input_path_str,
        '-vn', '-ac', '1', '-ar', '16000', tmp_wav_path
    ]
    if run_ffmpeg(ts_args):
        return tmp_wav_path

    # ØªÙ„Ø§Ø´ Ø³ÙˆÙ…: Ø¨Ø§ demuxing Ø³Ø§Ø¯Ù‡â€ŒØªØ±
    simple_args = [
        'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error', '-nostdin',
        '-i', input_path_str, '-vn', '-ac', '1', '-ar', '16000', tmp_wav_path
    ]
    if run_ffmpeg(simple_args):
        return tmp_wav_path

    # Ù†Ø§Ù…ÙˆÙÙ‚
    return None

def process_file_with_gpu(args: Tuple[str, str, str, int]) -> Tuple[bool, str, bool]:
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© ÙØ§ÛŒÙ„ Ø¨Ø§ GPU Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡

    Ø®Ø±ÙˆØ¬ÛŒ: (Ù…ÙˆÙÙ‚ÛŒØª/Ø´Ú©Ø³Øª, Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ØŒ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø³ØªØ®Ø±Ø§Ø¬ ffmpeg)
    """
    video_file, model_name, language, gpu_id = args
    try:
        # ØªÙ†Ø¸ÛŒÙ… GPU ÙÙ‚Ø· Ø§Ú¯Ø± GPU Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª
        if gpu_id != -1:
            torch.cuda.set_device(gpu_id)
        # Ú©Ù…Ú© Ø¨Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ CUDA
        os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True,max_split_size_mb:128')
        device_str = f"cuda:{gpu_id}" if gpu_id != -1 else "cpu"
        model = whisper.load_model(model_name, device=device_str)
        
        # Ø§Ø¨ØªØ¯Ø§ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØµÙˆØª Ø¨Ø§ ffmpeg (Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ/TS/Ø§Ø³ØªØ±ÛŒÙ…)
        extracted_wav = extract_audio_with_ffmpeg(video_file)
        ffmpeg_ok = extracted_wav is not None
        transcribe_input = extracted_wav if ffmpeg_ok else video_file

        # Ú©Ø§Ù‡Ø´ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø¯ÛŒÚ©ÙˆØ¯ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ú©Ù…ØªØ±
        result = model.transcribe(
            transcribe_input,
            language=language,
            condition_on_previous_text=False,
            beam_size=1
        )
        output_file = Path(video_file).with_suffix('.srt')
        
        with open(output_file, 'w', encoding='utf-8') as srt_file:
            for j, segment in enumerate(result['segments'], start=1):
                start_time = format_timestamp(segment['start'])
                end_time = format_timestamp(segment['end'])
                text = segment['text'].strip()
                srt_file.write(f"{j}\n{start_time} --> {end_time}\n{text}\n\n")
        
        print(f'âœ… Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ø¯Ø± ÙØ§ÛŒÙ„ {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ (GPU {gpu_id})')
        return True, '', ffmpeg_ok
    except RuntimeError as e:
        msg = str(e)
        # Ø§Ú¯Ø± OOM Ø´Ø¯ØŒ ÛŒÚ©Ø¨Ø§Ø± Ø¨Ø§ CPU ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯
        if 'CUDA out of memory' in msg or 'CUDA error' in msg:
            try:
                print(f'â™»ï¸ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø±ÙˆÛŒ CPU Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ú©Ù…Ø¨ÙˆØ¯ Ø­Ø§ÙØ¸Ù‡ GPU Ø¨Ø±Ø§ÛŒ {video_file}')
                model = whisper.load_model(model_name, device='cpu')
                extracted_wav = extract_audio_with_ffmpeg(video_file)
                transcribe_input = extracted_wav if extracted_wav else video_file
                result = model.transcribe(
                    transcribe_input,
                    language=language,
                    condition_on_previous_text=False,
                    beam_size=1
                )
                output_file = Path(video_file).with_suffix('.srt')
                with open(output_file, 'w', encoding='utf-8') as srt_file:
                    for j, segment in enumerate(result['segments'], start=1):
                        start_time = format_timestamp(segment['start'])
                        end_time = format_timestamp(segment['end'])
                        text = segment['text'].strip()
                        srt_file.write(f"{j}\n{start_time} --> {end_time}\n{text}\n\n")
                print(f'âœ… Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ø¯Ø± ÙØ§ÛŒÙ„ {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ (CPU fallback)')
                return True, '', extracted_wav is not None
            except Exception as e2:
                print(f'âŒ Ø´Ú©Ø³Øª ØªÙ„Ø§Ø´ CPU Ø¨Ø±Ø§ÛŒ {video_file}: {str(e2)}')
                return False, f'GPU OOM then CPU failed: {str(e2)}', False
        print(f'âŒ Ø®Ø·Ø§ÛŒ Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: {msg}')
        return False, msg, False
    except Exception as e:
        print(f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {video_file} Ø±ÙˆÛŒ GPU {gpu_id}: {str(e)}')
        return False, str(e), False

def process_directory(directory_path='.', model_name='large', language='ar', logfile: Optional[str] = None, ffmpeg_logfile: Optional[str] = None):
    print("ğŸ¬ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯! Ø³ÛŒØ³ØªÙ… ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Whisper Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯...")
    print("=" * 60)
    
    # Ø¨Ø±Ø±Ø³ÛŒ GPU Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
    available_gpus = get_available_gpus()
    if not available_gpus:
        print("âš ï¸  Ù‡ÛŒÚ† GPU Ø§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² CPU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        available_gpus = [-1]  # CPU
    else:
        print(f"ğŸ® ØªØ¹Ø¯Ø§Ø¯ {len(available_gpus)} Ú©Ø§Ø±Øª Ú¯Ø±Ø§ÙÛŒÚ© ÛŒØ§ÙØª Ø´Ø¯: {available_gpus}")

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ§ - Ø´Ø§Ù…Ù„ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ
    extensions = [
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ
        '*.mp4', '*.mp3', '*.m4a', '*.wav', '*.aac', '*.flac', '*.ogg', '*.mkv', '*.webm', '*.avi', '*.mov', '*.mpg',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ùˆ Ù¾Ø®Ø´
        '*.ts', '*.mts', '*.m2ts', '*.trp', '*.tp',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù¾Ø®Ø´
        '*.mxf', '*.gxf',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ DVD Ùˆ Ø¶Ø¨Ø·
        '*.vob', '*.ifo', '*.vro', '*.vdr',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ùˆ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡
        '*.3gp', '*.3g2',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª
        '*.asf', '*.wmv', '*.wma',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ RealMedia
        '*.rm', '*.rmvb', '*.ra', '*.ram',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø¶Ø¨Ø· ØªÙ„ÙˆÛŒØ²ÛŒÙˆÙ†
        '*.dvr-ms', '*.wtv', '*.rec', '*.pvr',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ú©ÙˆØ±Ø¯
        '*.mod', '*.tod',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ MPEG Ø§Ø¶Ø§ÙÛŒ
        '*.m2v', '*.m1v', '*.mp2', '*.mpa',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        '*.ac3', '*.eac3', '*.dts', '*.dtshd',
        '*.thd', '*.mlp', '*.aiff', '*.au', '*.snd',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Audible Ùˆ Ú©ØªØ§Ø¨ ØµÙˆØªÛŒ
        '*.aa', '*.aax', '*.m4b', '*.m4p',
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§Ù„Ø§
        '*.opus', '*.spx', '*.tta', '*.tak',
        '*.wv', '*.ape', '*.shn'
    ]
    all_files = []
    for ext in extensions:
        all_files.extend(glob.glob(os.path.join(directory_path, f'**/{ext}'), recursive=True))
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯Ù‡
    files_to_process = [f for f in all_files if not Path(f).with_suffix('.srt').exists()]
    
    if not files_to_process:
        print("âœ… Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù…Ø¯ÛŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return

    print(f"ğŸ“ ØªØ¹Ø¯Ø§Ø¯ {len(files_to_process)} ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ¯Ø§ Ø´Ø¯.")
    print("=" * 60)

    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ
    tasks = []
    for i, video_file in enumerate(files_to_process):
        gpu_id = available_gpus[i % len(available_gpus)]
        tasks.append((video_file, model_name, language, gpu_id))

    print(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ {len(files_to_process)} ÙØ§ÛŒÙ„...")
    print("=" * 60)

    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ú¯Ø²Ø§Ø±Ø´ Ù¾ÛŒØ´Ø±ÙØª Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
    successful = 0
    completed = 0
    total = len(files_to_process)
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯
    fail_log_path = Path(logfile) if logfile else Path('failed_media.log')
    ffmpeg_fail_log_path = Path(ffmpeg_logfile) if ffmpeg_logfile else Path('failed_ffmpeg.log')
    # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹
    try:
        with open(fail_log_path, 'w', encoding='utf-8') as lf:
            lf.write('')
        with open(ffmpeg_fail_log_path, 'w', encoding='utf-8') as lf2:
            lf2.write('')
    except Exception:
        pass

    with concurrent.futures.ProcessPoolExecutor(max_workers=len(available_gpus)) as executor:
        futures = [(executor.submit(process_file_with_gpu, t), t[0]) for t in tasks]
        for fut, src_file in concurrent.futures.as_completed([f for f, _ in futures]):
            pass
    # The above attempt to use as_completed with tuple unpacking is incorrect; implement correctly:
    with concurrent.futures.ProcessPoolExecutor(max_workers=len(available_gpus)) as executor:
        future_to_file = {executor.submit(process_file_with_gpu, t): t[0] for t in tasks}
        for fut in concurrent.futures.as_completed(future_to_file):
            src_file = future_to_file[fut]
            try:
                ok, err, ff_ok = fut.result()
            except Exception as ex:
                ok, err, ff_ok = False, str(ex), False
            completed += 1
            if ok:
                successful += 1
            else:
                try:
                    with open(fail_log_path, 'a', encoding='utf-8') as lf:
                        lf.write(f"{src_file}\t{err}\n")
                except Exception:
                    pass
            if not ff_ok:
                try:
                    with open(ffmpeg_fail_log_path, 'a', encoding='utf-8') as lf2:
                        lf2.write(f"{src_file}\n")
                except Exception:
                    pass
            remaining = total - completed
            print(f"ğŸ“¦ Ù¾ÛŒØ´Ø±ÙØª: {completed}/{total} Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ | Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡: {remaining}")
    failed = total - successful
    
    print("=" * 60)
    print(f"ğŸ‰ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print(f"âœ… Ù…ÙˆÙÙ‚: {successful} ÙØ§ÛŒÙ„")
    print(f"âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {failed} ÙØ§ÛŒÙ„")
    print(f"ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹: {len(files_to_process)} ÙØ§ÛŒÙ„")
    print("=" * 60)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ùˆ ØµÙˆØªÛŒ Ø¨Ù‡ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Whisper')
    parser.add_argument('--directory', default='.', help='Ù…Ø³ÛŒØ± Ù¾ÙˆØ´Ù‡ Ø­Ø§ÙˆÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ùˆ ØµÙˆØªÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ù¾ÙˆØ´Ù‡ ÙØ¹Ù„ÛŒ)')
    parser.add_argument('--model', default='large', help='Ù†Ø§Ù… Ù…Ø¯Ù„ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: large)')
    parser.add_argument('--language', default='ar', help='Ú©Ø¯ Ø²Ø¨Ø§Ù† (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: ar)')
    parser.add_argument('--logfile', default='failed_media.log', help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ø´Ú©Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´')
    parser.add_argument('--ffmpeg-logfile', default='failed_ffmpeg.log', help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ø´Ú©Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ffmpeg')
    
    args = parser.parse_args()
    
    process_directory(args.directory, args.model, args.language, args.logfile, args.ffmpeg_logfile)